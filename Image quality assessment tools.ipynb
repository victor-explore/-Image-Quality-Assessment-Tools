{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyON7f2SWndX44rfX8Nm0+tk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Step 1: Setup environment**"],"metadata":{"id":"1RcpqHFK0pVs"}},{"cell_type":"code","source":["# Install necessary libraries\n","!pip install lpips scikit-image\n","\n","# Import required libraries\n","import os\n","import numpy as np\n","from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","import lpips\n","import pandas as pd\n","from scipy.stats import spearmanr\n","import matplotlib.pyplot as plt\n","\n","print(\"Environment setup completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZUs9byI03Xt","executionInfo":{"status":"ok","timestamp":1711981065277,"user_tz":-330,"elapsed":9776,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"58c58b05-3689-40c0-f832-b87dffc0bddd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lpips in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.17.1+cu121)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.25.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.2)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips) (12.4.99)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n","Environment setup completed.\n"]}]},{"cell_type":"markdown","source":["**lpips:** Imported directly, this library is used for evaluating perceptual image patch similarity, which differs from traditional metrics like PSNR and SSIM by focusing on perceptual differences rather than pixel-level differences."],"metadata":{"id":"bC5hQaCu-0Lv"}},{"cell_type":"markdown","source":["**scikit-image:** A collection of algorithms for image processing in Python. It's widely used for tasks such as image segmentation, geometric transformations, color space manipulation, analysis, filtering, morphology, feature detection, and more."],"metadata":{"id":"EZo35QVO-3mR"}},{"cell_type":"markdown","source":["**os:** A module for interacting with the operating system, useful for file path operations, directory navigation, and more."],"metadata":{"id":"y_rMhFvc-7GQ"}},{"cell_type":"markdown","source":["**numpy:** A fundamental package for scientific computing in Python, providing support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays."],"metadata":{"id":"Z5mPpVd7--Vp"}},{"cell_type":"markdown","source":["**peak_signal_noise_ratio (PSNR):** A metric used to measure the quality of reconstruction of lossy compression codecs. It's commonly used in image processing to compare the quality of an output image to its original."],"metadata":{"id":"lzXktzGy_CEu"}},{"cell_type":"markdown","source":["**structural_similarity (SSIM):** A method for measuring the similarity between two images. It's often used to assess the quality of images after compression or other types of processing."],"metadata":{"id":"qJ_zu6cP_Jqf"}},{"cell_type":"markdown","source":["**pandas:** A library providing high-performance, easy-to-use data structures, and data analysis tools."],"metadata":{"id":"Cizq3QB2_JmK"}},{"cell_type":"markdown","source":["**from scipy.stats import spearmanr:** Imports a function for calculating the Spearman rank-order correlation coefficient, which measures the monotonicity of the relationship between two datasets."],"metadata":{"id":"bUIN7iMa_Ue3"}},{"cell_type":"markdown","source":["**matplotlib.pyplot:** A plotting library that provides a MATLAB-like interface for making plots and visualizations in Python."],"metadata":{"id":"fg_otipz_YPx"}},{"cell_type":"markdown","source":["### **Step 2: Download and extract the dataset**"],"metadata":{"id":"aIYw9H2V1bPE"}},{"cell_type":"code","source":["# Download the dataset\n","!wget http://ece.iisc.ac.in/~rajivs/courses/aip2016/hw5.rar\n","\n","# Extract the contents of the downloaded archive\n","!unrar x hw5.rar\n","\n","print(\"Dataset downloaded and extracted.\")\n","\n","# Extract gblur.rar and refimgs.rar\n","!unrar x hw5/gblur.rar\n","!unrar x hw5/refimgs.rar\n","\n","print(\"Folders extracted:\")\n","for folder in [\"gblur\", \"refimgs\"]:\n","    folder_path = folder\n","    if os.path.exists(folder_path):\n","        print(f\"- {folder}: {len(os.listdir(folder_path))} files\")\n","    else:\n","        print(f\"- {folder}: Folder not found\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KimUpHoW1fvC","executionInfo":{"status":"ok","timestamp":1711981121591,"user_tz":-330,"elapsed":56320,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"c41aafcf-d7de-4c9c-f970-5d4fffb7d446"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-04-01 14:17:45--  http://ece.iisc.ac.in/~rajivs/courses/aip2016/hw5.rar\n","Resolving ece.iisc.ac.in (ece.iisc.ac.in)... 13.71.53.212\n","Connecting to ece.iisc.ac.in (ece.iisc.ac.in)|13.71.53.212|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://ece.iisc.ac.in/~rajivs/courses/aip2016/hw5.rar [following]\n","--2024-04-01 14:17:45--  https://ece.iisc.ac.in/~rajivs/courses/aip2016/hw5.rar\n","Connecting to ece.iisc.ac.in (ece.iisc.ac.in)|13.71.53.212|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 85354498 (81M)\n","Saving to: ‘hw5.rar.8’\n","\n","hw5.rar.8           100%[===================>]  81.40M  12.6MB/s    in 7.7s    \n","\n","2024-04-01 14:17:54 (10.5 MB/s) - ‘hw5.rar.8’ saved [85354498/85354498]\n","\n","\n","UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n","\n","\n","Extracting from hw5.rar\n","\n","\n","Would you like to replace the existing file hw5/gblur.rar\n","69342543 bytes, modified on 2016-03-23 18:09\n","with a new one\n","69342543 bytes, modified on 2016-03-23 18:09\n","\n","[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n","\n","Extracting  hw5/gblur.rar                                                \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  hw5/hw5.mat                                                  \b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  hw5/readme.txt                                               \b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  hw5/refimgs.rar                                              \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n","Dataset downloaded and extracted.\n","\n","UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n","\n","\n","Extracting from hw5/gblur.rar\n","\n","\n","Would you like to replace the existing file gblur/img1.bmp\n","1179702 bytes, modified on 2003-03-20 19:37\n","with a new one\n","1179702 bytes, modified on 2003-03-20 19:37\n","\n","[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n","\n","Extracting  gblur/img1.bmp                                               \b\b\b\b  0%\b\b\b\b\b  OK \n","Extracting  gblur/img10.bmp                                              \b\b\b\b  0%\b\b\b\b\b  OK \n","Extracting  gblur/img100.bmp                                             \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n","Extracting  gblur/img101.bmp                                             \b\b\b\b  1%\b\b\b\b\b  OK \n","Extracting  gblur/img102.bmp                                             \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b\b  OK \n","Extracting  gblur/img103.bmp                                             \b\b\b\b  2%\b\b\b\b\b  OK \n","Extracting  gblur/img104.bmp                                             \b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n","Extracting  gblur/img105.bmp                                             \b\b\b\b  3%\b\b\b\b\b  OK \n","Extracting  gblur/img106.bmp                                             \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b\b  OK \n","Extracting  gblur/img107.bmp                                             \b\b\b\b  4%\b\b\b\b\b  OK \n","Extracting  gblur/img108.bmp                                             \b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n","Extracting  gblur/img109.bmp                                             \b\b\b\b  5%\b\b\b\b\b  OK \n","Extracting  gblur/img11.bmp                                              \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b\b  OK \n","Extracting  gblur/img110.bmp                                             \b\b\b\b  6%\b\b\b\b\b  OK \n","Extracting  gblur/img111.bmp                                             \b\b\b\b  6%\b\b\b\b  7%\b\b\b\b\b  OK \n","Extracting  gblur/img112.bmp                                             \b\b\b\b  7%\b\b\b\b\b  OK \n","Extracting  gblur/img113.bmp                                             \b\b\b\b  8%\b\b\b\b\b  OK \n","Extracting  gblur/img114.bmp                                             \b\b\b\b  8%\b\b\b\b\b  OK \n","Extracting  gblur/img115.bmp                                             \b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n","Extracting  gblur/img116.bmp                                             \b\b\b\b  9%\b\b\b\b\b  OK \n","Extracting  gblur/img117.bmp                                             \b\b\b\b  9%\b\b\b\b\b  OK \n","Extracting  gblur/img118.bmp                                             \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b\b  OK \n","Extracting  gblur/img119.bmp                                             \b\b\b\b 10%\b\b\b\b\b  OK \n","Extracting  gblur/img12.bmp                                              \b\b\b\b 10%\b\b\b\b 11%\b\b\b\b\b  OK \n","Extracting  gblur/img120.bmp                                             \b\b\b\b 11%\b\b\b\b\b  OK \n","Extracting  gblur/img121.bmp                                             \b\b\b\b 11%\b\b\b\b\b  OK \n","Extracting  gblur/img122.bmp                                             \b\b\b\b 11%\b\b\b\b 12%\b\b\b\b\b  OK \n","Extracting  gblur/img123.bmp                                             \b\b\b\b 12%\b\b\b\b\b  OK \n","Extracting  gblur/img124.bmp                                             \b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n","Extracting  gblur/img125.bmp                                             \b\b\b\b 13%\b\b\b\b\b  OK \n","Extracting  gblur/img126.bmp                                             \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b\b  OK \n","Extracting  gblur/img127.bmp                                             \b\b\b\b 14%\b\b\b\b\b  OK \n","Extracting  gblur/img128.bmp                                             \b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n","Extracting  gblur/img129.bmp                                             \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n","Extracting  gblur/img13.bmp                                              \b\b\b\b 16%\b\b\b\b\b  OK \n","Extracting  gblur/img130.bmp                                             \b\b\b\b 16%\b\b\b\b 17%\b\b\b\b\b  OK \n","Extracting  gblur/img131.bmp                                             \b\b\b\b 17%\b\b\b\b\b  OK \n","Extracting  gblur/img132.bmp                                             \b\b\b\b 17%\b\b\b\b\b  OK \n","Extracting  gblur/img133.bmp                                             \b\b\b\b 17%\b\b\b\b 18%\b\b\b\b\b  OK \n","Extracting  gblur/img134.bmp                                             \b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n","Extracting  gblur/img135.bmp                                             \b\b\b\b 19%\b\b\b\b\b  OK \n","Extracting  gblur/img136.bmp                                             \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b\b  OK \n","Extracting  gblur/img137.bmp                                             \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b\b  OK \n","Extracting  gblur/img138.bmp                                             \b\b\b\b 21%\b\b\b\b\b  OK \n","Extracting  gblur/img139.bmp                                             \b\b\b\b 21%\b\b\b\b\b  OK \n","Extracting  gblur/img14.bmp                                              \b\b\b\b 21%\b\b\b\b 22%\b\b\b\b\b  OK \n","Extracting  gblur/img140.bmp                                             \b\b\b\b 22%\b\b\b\b\b  OK \n","Extracting  gblur/img141.bmp                                             \b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n","Extracting  gblur/img142.bmp                                             \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b\b  OK \n","Extracting  gblur/img143.bmp                                             \b\b\b\b 24%\b\b\b\b\b  OK \n","Extracting  gblur/img144.bmp                                             \b\b\b\b 24%\b\b\b\b 25%\b\b\b\b\b  OK \n","Extracting  gblur/img145.bmp                                             \b\b\b\b 25%\b\b\b\b\b  OK \n","Extracting  gblur/img146.bmp                                             \b\b\b\b 25%\b\b\b\b 26%\b\b\b\b\b  OK \n","Extracting  gblur/img147.bmp                                             \b\b\b\b 26%\b\b\b\b 27%\b\b\b\b\b  OK \n","Extracting  gblur/img148.bmp                                             \b\b\b\b 27%\b\b\b\b\b  OK \n","Extracting  gblur/img149.bmp                                             \b\b\b\b 27%\b\b\b\b 28%\b\b\b\b\b  OK \n","Extracting  gblur/img15.bmp                                              \b\b\b\b 28%\b\b\b\b 29%\b\b\b\b\b  OK \n","Extracting  gblur/img150.bmp                                             \b\b\b\b 29%\b\b\b\b\b  OK \n","Extracting  gblur/img151.bmp                                             \b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b\b  OK \n","Extracting  gblur/img152.bmp                                             \b\b\b\b 31%\b\b\b\b 32%\b\b\b\b\b  OK \n","Extracting  gblur/img153.bmp                                             \b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n","Extracting  gblur/img154.bmp                                             \b\b\b\b 33%\b\b\b\b\b  OK \n","Extracting  gblur/img155.bmp                                             \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b\b  OK \n","Extracting  gblur/img156.bmp                                             \b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b\b  OK \n","Extracting  gblur/img157.bmp                                             \b\b\b\b 36%\b\b\b\b\b  OK \n","Extracting  gblur/img158.bmp                                             \b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n","Extracting  gblur/img159.bmp                                             \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b\b  OK \n","Extracting  gblur/img16.bmp                                              \b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n","Extracting  gblur/img160.bmp                                             \b\b\b\b 39%\b\b\b\b\b  OK \n","Extracting  gblur/img161.bmp                                             \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b\b  OK \n","Extracting  gblur/img162.bmp                                             \b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n","Extracting  gblur/img163.bmp                                             \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b\b  OK \n","Extracting  gblur/img164.bmp                                             \b\b\b\b 42%\b\b\b\b\b  OK \n","Extracting  gblur/img165.bmp                                             \b\b\b\b 42%\b\b\b\b 43%\b\b\b\b\b  OK \n","Extracting  gblur/img166.bmp                                             \b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n","Extracting  gblur/img167.bmp                                             \b\b\b\b 44%\b\b\b\b 45%\b\b\b\b\b  OK \n","Extracting  gblur/img168.bmp                                             \b\b\b\b 45%\b\b\b\b\b  OK \n","Extracting  gblur/img169.bmp                                             \b\b\b\b 45%\b\b\b\b 46%\b\b\b\b\b  OK \n","Extracting  gblur/img17.bmp                                              \b\b\b\b 46%\b\b\b\b\b  OK \n","Extracting  gblur/img170.bmp                                             \b\b\b\b 47%\b\b\b\b\b  OK \n","Extracting  gblur/img171.bmp                                             \b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n","Extracting  gblur/img172.bmp                                             \b\b\b\b 48%\b\b\b\b 49%\b\b\b\b\b  OK \n","Extracting  gblur/img173.bmp                                             \b\b\b\b 49%\b\b\b\b\b  OK \n","Extracting  gblur/img174.bmp                                             \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b\b  OK \n","Extracting  gblur/img18.bmp                                              \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b\b  OK \n","Extracting  gblur/img19.bmp                                              \b\b\b\b 51%\b\b\b\b\b  OK \n","Extracting  gblur/img2.bmp                                               \b\b\b\b 52%\b\b\b\b\b  OK \n","Extracting  gblur/img20.bmp                                              \b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n","Extracting  gblur/img21.bmp                                              \b\b\b\b 53%\b\b\b\b\b  OK \n","Extracting  gblur/img22.bmp                                              \b\b\b\b 53%\b\b\b\b 54%\b\b\b\b\b  OK \n","Extracting  gblur/img23.bmp                                              \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b\b  OK \n","Extracting  gblur/img24.bmp                                              \b\b\b\b 55%\b\b\b\b\b  OK \n","Extracting  gblur/img25.bmp                                              \b\b\b\b 55%\b\b\b\b\b  OK \n","Extracting  gblur/img26.bmp                                              \b\b\b\b 55%\b\b\b\b 56%\b\b\b\b\b  OK \n","Extracting  gblur/img27.bmp                                              \b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n","Extracting  gblur/img28.bmp                                              \b\b\b\b 57%\b\b\b\b\b  OK \n","Extracting  gblur/img29.bmp                                              \b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n","Extracting  gblur/img3.bmp                                               \b\b\b\b 58%\b\b\b\b\b  OK \n","Extracting  gblur/img30.bmp                                              \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b\b  OK \n","Extracting  gblur/img31.bmp                                              \b\b\b\b 59%\b\b\b\b\b  OK \n","Extracting  gblur/img32.bmp                                              \b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n","Extracting  gblur/img33.bmp                                              \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b\b  OK \n","Extracting  gblur/img34.bmp                                              \b\b\b\b 61%\b\b\b\b\b  OK \n","Extracting  gblur/img35.bmp                                              \b\b\b\b 61%\b\b\b\b 62%\b\b\b\b\b  OK \n","Extracting  gblur/img36.bmp                                              \b\b\b\b 62%\b\b\b\b\b  OK \n","Extracting  gblur/img37.bmp                                              \b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n","Extracting  gblur/img38.bmp                                              \b\b\b\b 63%\b\b\b\b\b  OK \n","Extracting  gblur/img39.bmp                                              \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n","Extracting  gblur/img4.bmp                                               \b\b\b\b 64%\b\b\b\b 65%\b\b\b\b\b  OK \n","Extracting  gblur/img40.bmp                                              \b\b\b\b 65%\b\b\b\b\b  OK \n","Extracting  gblur/img41.bmp                                              \b\b\b\b 65%\b\b\b\b 66%\b\b\b\b\b  OK \n","Extracting  gblur/img42.bmp                                              \b\b\b\b 66%\b\b\b\b\b  OK \n","Extracting  gblur/img43.bmp                                              \b\b\b\b 66%\b\b\b\b\b  OK \n","Extracting  gblur/img44.bmp                                              \b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n","Extracting  gblur/img45.bmp                                              \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b\b  OK \n","Extracting  gblur/img46.bmp                                              \b\b\b\b 68%\b\b\b\b 69%\b\b\b\b\b  OK \n","Extracting  gblur/img47.bmp                                              \b\b\b\b 69%\b\b\b\b\b  OK \n","Extracting  gblur/img48.bmp                                              \b\b\b\b 69%\b\b\b\b\b  OK \n","Extracting  gblur/img49.bmp                                              \b\b\b\b 69%\b\b\b\b 70%\b\b\b\b\b  OK \n","Extracting  gblur/img5.bmp                                               \b\b\b\b 70%\b\b\b\b\b  OK \n","Extracting  gblur/img50.bmp                                              \b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n","Extracting  gblur/img51.bmp                                              \b\b\b\b 71%\b\b\b\b 72%\b\b\b\b\b  OK \n","Extracting  gblur/img52.bmp                                              \b\b\b\b 72%\b\b\b\b\b  OK \n","Extracting  gblur/img53.bmp                                              \b\b\b\b 72%\b\b\b\b\b  OK \n","Extracting  gblur/img54.bmp                                              \b\b\b\b 72%\b\b\b\b 73%\b\b\b\b\b  OK \n","Extracting  gblur/img55.bmp                                              \b\b\b\b 73%\b\b\b\b\b  OK \n","Extracting  gblur/img56.bmp                                              \b\b\b\b 73%\b\b\b\b 74%\b\b\b\b\b  OK \n","Extracting  gblur/img57.bmp                                              \b\b\b\b 74%\b\b\b\b\b  OK \n","Extracting  gblur/img58.bmp                                              \b\b\b\b 74%\b\b\b\b 75%\b\b\b\b\b  OK \n","Extracting  gblur/img59.bmp                                              \b\b\b\b 75%\b\b\b\b\b  OK \n","Extracting  gblur/img6.bmp                                               \b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n","Extracting  gblur/img60.bmp                                              \b\b\b\b 76%\b\b\b\b\b  OK \n","Extracting  gblur/img61.bmp                                              \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b\b  OK \n","Extracting  gblur/img62.bmp                                              \b\b\b\b 77%\b\b\b\b 78%\b\b\b\b\b  OK \n","Extracting  gblur/img63.bmp                                              \b\b\b\b 78%\b\b\b\b\b  OK \n","Extracting  gblur/img64.bmp                                              \b\b\b\b 78%\b\b\b\b 79%\b\b\b\b\b  OK \n","Extracting  gblur/img65.bmp                                              \b\b\b\b 79%\b\b\b\b\b  OK \n","Extracting  gblur/img66.bmp                                              \b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  gblur/img67.bmp                                              \b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  gblur/img68.bmp                                              \b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n","Extracting  gblur/img69.bmp                                              \b\b\b\b 81%\b\b\b\b\b  OK \n","Extracting  gblur/img7.bmp                                               \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b\b  OK \n","Extracting  gblur/img70.bmp                                              \b\b\b\b 82%\b\b\b\b\b  OK \n","Extracting  gblur/img71.bmp                                              \b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n","Extracting  gblur/img72.bmp                                              \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n","Extracting  gblur/img73.bmp                                              \b\b\b\b 84%\b\b\b\b\b  OK \n","Extracting  gblur/img74.bmp                                              \b\b\b\b 84%\b\b\b\b 85%\b\b\b\b\b  OK \n","Extracting  gblur/img75.bmp                                              \b\b\b\b 85%\b\b\b\b\b  OK \n","Extracting  gblur/img76.bmp                                              \b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n","Extracting  gblur/img77.bmp                                              \b\b\b\b 86%\b\b\b\b\b  OK \n","Extracting  gblur/img78.bmp                                              \b\b\b\b 86%\b\b\b\b\b  OK \n","Extracting  gblur/img79.bmp                                              \b\b\b\b 86%\b\b\b\b 87%\b\b\b\b\b  OK \n","Extracting  gblur/img8.bmp                                               \b\b\b\b 87%\b\b\b\b 88%\b\b\b\b\b  OK \n","Extracting  gblur/img80.bmp                                              \b\b\b\b 88%\b\b\b\b\b  OK \n","Extracting  gblur/img81.bmp                                              \b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n","Extracting  gblur/img82.bmp                                              \b\b\b\b 89%\b\b\b\b\b  OK \n","Extracting  gblur/img83.bmp                                              \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b\b  OK \n","Extracting  gblur/img84.bmp                                              \b\b\b\b 90%\b\b\b\b\b  OK \n","Extracting  gblur/img85.bmp                                              \b\b\b\b 90%\b\b\b\b 91%\b\b\b\b\b  OK \n","Extracting  gblur/img86.bmp                                              \b\b\b\b 91%\b\b\b\b\b  OK \n","Extracting  gblur/img87.bmp                                              \b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n","Extracting  gblur/img88.bmp                                              \b\b\b\b 92%\b\b\b\b\b  OK \n","Extracting  gblur/img89.bmp                                              \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b\b  OK \n","Extracting  gblur/img9.bmp                                               \b\b\b\b 93%\b\b\b\b\b  OK \n","Extracting  gblur/img90.bmp                                              \b\b\b\b 93%\b\b\b\b 94%\b\b\b\b\b  OK \n","Extracting  gblur/img91.bmp                                              \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b\b  OK \n","Extracting  gblur/img92.bmp                                              \b\b\b\b 95%\b\b\b\b 96%\b\b\b\b\b  OK \n","Extracting  gblur/img93.bmp                                              \b\b\b\b 96%\b\b\b\b\b  OK \n","Extracting  gblur/img94.bmp                                              \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n","Extracting  gblur/img95.bmp                                              \b\b\b\b 97%\b\b\b\b 98%\b\b\b\b\b  OK \n","Extracting  gblur/img96.bmp                                              \b\b\b\b 98%\b\b\b\b\b  OK \n","Extracting  gblur/img97.bmp                                              \b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n","Extracting  gblur/img98.bmp                                              \b\b\b\b 99%\b\b\b\b\b  OK \n","Extracting  gblur/img99.bmp                                              \b\b\b\b 99%\b\b\b\b\b  OK \n","Extracting  gblur/info.txt                                               \b\b\b\b 99%\b\b\b\b\b  OK \n","Extracting  gblur/Thumbs.db                                              \b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n","\n","UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n","\n","\n","Extracting from hw5/refimgs.rar\n","\n","\n","Would you like to replace the existing file refimgs/bikes.bmp\n","1179702 bytes, modified on 2002-04-05 17:21\n","with a new one\n","1179702 bytes, modified on 2002-04-05 17:21\n","\n","[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n","\n","Extracting  refimgs/bikes.bmp                                            \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b\b  OK \n","Extracting  refimgs/building2.bmp                                        \b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n","Extracting  refimgs/buildings.bmp                                        \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b\b  OK \n","Extracting  refimgs/caps.bmp                                             \b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n","Extracting  refimgs/carnivaldolls.bmp                                    \b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n","Extracting  refimgs/cemetry.bmp                                          \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n","Extracting  refimgs/churchandcapitol.bmp                                 \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b\b  OK \n","Extracting  refimgs/coinsinfountain.bmp                                  \b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b\b  OK \n","Extracting  refimgs/dancers.bmp                                          \b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b\b  OK \n","Extracting  refimgs/flowersonih35.bmp                                    \b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b\b  OK \n","Extracting  refimgs/house.bmp                                            \b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n","Extracting  refimgs/lighthouse.bmp                                       \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n","Extracting  refimgs/lighthouse2.bmp                                      \b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b\b  OK \n","Extracting  refimgs/manfishing.bmp                                       \b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b\b  OK \n","Extracting  refimgs/monarch.bmp                                          \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n","Extracting  refimgs/ocean.bmp                                            \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b\b  OK \n","Extracting  refimgs/paintedhouse.bmp                                     \b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n","Extracting  refimgs/parrots.bmp                                          \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n","Extracting  refimgs/plane.bmp                                            \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b\b  OK \n","Extracting  refimgs/rapids.bmp                                           \b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b\b  OK \n","Extracting  refimgs/sailing1.bmp                                         \b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b\b  OK \n","Extracting  refimgs/sailing2.bmp                                         \b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b\b  OK \n","Extracting  refimgs/sailing3.bmp                                         \b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b\b  OK \n","Extracting  refimgs/sailing4.bmp                                         \b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  refimgs/statue.bmp                                           \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n","Extracting  refimgs/stream.bmp                                           \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b\b  OK \n","Extracting  refimgs/studentsculpture.bmp                                 \b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n","Extracting  refimgs/Thumbs.db                                            \b\b\b\b 93%\b\b\b\b\b  OK \n","Extracting  refimgs/woman.bmp                                            \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n","Extracting  refimgs/womanhat.bmp                                         \b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n","Folders extracted:\n","- gblur: 176 files\n","- refimgs: 30 files\n"]}]},{"cell_type":"markdown","source":["This section of the code is crucial for ensuring that the necessary data for the project is available and organized. By downloading and extracting specific parts of the dataset, it prepares the ground for subsequent image processing or analysis tasks."],"metadata":{"id":"dlWQT4zt_f_h"}},{"cell_type":"markdown","source":["### **Step 3: Implement the perceptual quality metrics**"],"metadata":{"id":"6WPhHW2p5CD1"}},{"cell_type":"code","source":["import numpy as np\n","from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","import lpips\n","\n","def calculate_psnr(img1, img2):\n","    return peak_signal_noise_ratio(img1, img2)\n","\n","def calculate_ssim(img1, img2):\n","    return structural_similarity(img1, img2, channel_axis=2)\n","\n","def calculate_lpips_vgg(img1, img2):\n","    loss_fn = lpips.LPIPS(net='vgg')\n","    img1_tensor = lpips.im2tensor(img1)\n","    img2_tensor = lpips.im2tensor(img2)\n","    return loss_fn(img1_tensor, img2_tensor).item()\n","\n","def calculate_lpips_alexnet(img1, img2):\n","    loss_fn = lpips.LPIPS(net='alex')\n","    img1_tensor = lpips.im2tensor(img1)\n","    img2_tensor = lpips.im2tensor(img2)\n","    return loss_fn(img1_tensor, img2_tensor).item()\n","\n","print(\"Perceptual quality metrics implemented.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MX4lQ5vm2rsq","executionInfo":{"status":"ok","timestamp":1711981121591,"user_tz":-330,"elapsed":14,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"6631b136-3995-4ab4-d04d-f9c893e76544"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perceptual quality metrics implemented.\n"]}]},{"cell_type":"markdown","source":["**calculate_psnr(img1, img2)**\n","PSNR (Peak Signal-to-Noise Ratio) is a widely used measure to assess the quality of reconstruction of lossy compression codecs. The higher the PSNR, the better the quality of the compressed or reconstructed image. It is expressed in logarithmic decibels (dB) scale."],"metadata":{"id":"4XoaXccrAL7I"}},{"cell_type":"markdown","source":["**calculate_ssim(img1, img2)**\n","SSIM (Structural Similarity Index) is a method for measuring the similarity between two images. The SSIM index is a decimal value between -1 and 1; 1 indicates perfect similarity. It considers changes in structural information, luminance, and contrast, providing a more accurate measure of perceptual similarity than PSNR.\n","Usage: This function calculates the SSIM of two images, specifying that the comparison should be made color channel-wise (channel_axis=2) for color images."],"metadata":{"id":"I-OeE24IAS_d"}},{"cell_type":"markdown","source":["**calculate_lpips_vgg(img1, img2): Uses a VGG network.\n","calculate_lpips_alexnet(img1, img2): Uses an AlexNet network.**\n","LPIPS  (Learned Perceptual Image Patch Similarity) measures the perceptual similarity between two images using deep networks. Unlike PSNR and SSIM, LPIPS uses learned features from deep networks (VGG, AlexNet) to assess perceptual similarity, which can align more closely with human judgment. It's particularly useful for tasks where fine-grained perceptual differences are critical, such as in image generation or super-resolution.\n","Usage: Both functions convert input images to tensors, then compute the LPIPS score using the specified network (VGG or AlexNet). This approach provides flexibility in choosing the underlying neural network model based on the specific requirements or expected characteristics of the images being compared."],"metadata":{"id":"CyFVnn8dAklV"}},{"cell_type":"markdown","source":["### **Step 4: Load and preprocess the data**"],"metadata":{"id":"cSriD--BB6Wg"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","import scipy.io\n","\n","# Load reference image names\n","ref_names = scipy.io.loadmat('hw5/hw5.mat')['refnames_blur'][0]\n","\n","# Load human opinion scores\n","dmos_scores = scipy.io.loadmat('hw5/hw5.mat')['blur_dmos'][0]\n","\n","# Load original image indicators\n","is_original = scipy.io.loadmat('hw5/hw5.mat')['blur_orgs'][0]\n","\n","# Initialize lists to store image paths and scores\n","distorted_imgs = []\n","reference_imgs = []\n","scores = []\n","\n","# Iterate over distorted images\n","for i, img_name in enumerate(os.listdir('gblur')):\n","    if img_name.endswith('.bmp'):\n","        # Load distorted image\n","        distorted_img_path = os.path.join('gblur', img_name)\n","        distorted_imgs.append(distorted_img_path)\n","\n","        # Find corresponding reference image\n","        if i < len(ref_names):\n","            ref_name = ref_names[i][0]\n","            ref_img_path = os.path.join('refimgs', ref_name)\n","            reference_imgs.append(ref_img_path)\n","        else:\n","            reference_imgs.append(None)\n","\n","        # Store score if not an original image\n","        if i < len(is_original) and not is_original[i]:\n","            scores.append(dmos_scores[i])\n","        else:\n","            scores.append(None)\n","\n","print(f\"Number of distorted images: {len(distorted_imgs)}\")\n","print(f\"Number of reference images: {len([img for img in reference_imgs if img is not None])}\")\n","print(f\"Number of valid scores: {len([s for s in scores if s is not None])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjN2faE1CGwM","executionInfo":{"status":"ok","timestamp":1711981297135,"user_tz":-330,"elapsed":515,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"474a1dd8-31cc-4ed9-d1e2-4d2aa8266d16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of distorted images: 174\n","Number of reference images: 172\n","Number of valid scores: 143\n"]}]},{"cell_type":"markdown","source":["The code loads three pieces of information from a .mat file:\n","\n","\n","*   ref_names: Names of reference images corresponding to the distorted images.\n","*   dmos_scores: Differential Mean Opinion Scores (DMOS), which are human-assigned scores indicating the perceived quality of the distorted images relative to their references. Lower scores typically mean better perceived quality.\n","*   is_original: A binary indicator showing whether an image is an original (reference) image.\n","\n","\n"],"metadata":{"id":"2VyQpe5xBHIG"}},{"cell_type":"markdown","source":["The code then initializes lists to store paths to distorted images, reference images, and DMOS scores. It iterates over the distorted images stored in a directory named gblur, performing the following steps for each image:\n","\n","\n","*   Distorted Image Processing: Adds the path of the distorted image to the distorted_imgs list.\n","*   Reference Image Matching: Attempts to match each distorted image with its reference image using the ref_names list. If a match is found within the bounds of ref_names, it adds the path to the reference_imgs list. Otherwise, it appends None.\n","*   DMOS Score Association: Associates a DMOS score with each distorted image if the image is not marked as an original in is_original. If the image is an original or if it exceeds the bounds of the is_original list, it appends None."],"metadata":{"id":"A2UZL_-SBYMV"}},{"cell_type":"markdown","source":["### **Step 5: Compute quality scores**"],"metadata":{"id":"XxAYYyiGCevI"}},{"cell_type":"code","source":["def calculate_psnr(img1, img2):\n","    data_range = np.max(img2) - np.min(img2)\n","    return peak_signal_noise_ratio(img1, img2, data_range=data_range)"],"metadata":{"id":"zYvKMpqLDMKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","from skimage.transform import resize\n","\n","# Initialize LPIPS models\n","lpips_vgg = lpips.LPIPS(net='vgg')\n","lpips_alexnet = lpips.LPIPS(net='alex')\n","\n","# Initialize lists to store quality scores\n","psnr_scores = []\n","ssim_scores = []\n","lpips_vgg_scores = []\n","lpips_alexnet_scores = []\n","\n","# Iterate over distorted images and calculate quality scores\n","for i, (distorted_img_path, ref_img_path) in enumerate(tqdm(zip(distorted_imgs, reference_imgs), total=len(distorted_imgs))):\n","    if ref_img_path is not None:\n","        # Load distorted and reference images\n","        distorted_img = np.array(Image.open(distorted_img_path).convert('RGB'))\n","        ref_img = np.array(Image.open(ref_img_path).convert('RGB'))\n","\n","        # Resize distorted image to match reference image dimensions\n","        distorted_img_resized = resize(distorted_img, ref_img.shape[:2], anti_aliasing=True, preserve_range=True)\n","\n","        # Calculate quality scores\n","        psnr = calculate_psnr(distorted_img_resized, ref_img)\n","        ssim = calculate_ssim(distorted_img_resized, ref_img)\n","        lpips_vgg_score = lpips_vgg(lpips.im2tensor(distorted_img_resized), lpips.im2tensor(ref_img)).item()\n","        lpips_alexnet_score = lpips_alexnet(lpips.im2tensor(distorted_img_resized), lpips.im2tensor(ref_img)).item()\n","\n","        psnr_scores.append(psnr)\n","        ssim_scores.append(ssim)\n","        lpips_vgg_scores.append(lpips_vgg_score)\n","        lpips_alexnet_scores.append(lpips_alexnet_score)\n","    else:\n","        psnr_scores.append(None)\n","        ssim_scores.append(None)\n","        lpips_vgg_scores.append(None)\n","        lpips_alexnet_scores.append(None)\n","\n","print(\"Quality scores computed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_Nc78pzCkCN","executionInfo":{"status":"ok","timestamp":1711985495621,"user_tz":-330,"elapsed":1488627,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"45ad9996-bdcf-47d6-deaf-e98ff9151603"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/vgg.pth\n","Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 174/174 [24:43<00:00,  8.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Quality scores computed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["Four lists are initialized to store the quality scores calculated for each image pair:\n","\n","\n","*   psnr_scores\n","*   ssim_scores\n","*   lpips_vgg_scores\n","*   lpips_alexnet_scores\n","\n"],"metadata":{"id":"6ra9WeI_BrAX"}},{"cell_type":"markdown","source":["**Image Loading and Resizing:** Both the distorted and reference images are loaded and converted to RGB. The distorted image is resized to match the reference image's dimensions to ensure comparability."],"metadata":{"id":"PIE4hyemFzRd"}},{"cell_type":"markdown","source":["Quality Metric Calculation:\n","\n","\n","*   **PSNR:** The Peak Signal-to-Noise Ratio is calculated between the resized distorted image and the reference image. The data_range is dynamically determined based on the reference image's pixel value range to improve accuracy.\n","*   **SSIM:** The Structural Similarity Index is calculated to measure the perceptual similarity between the two images.\n","*   **LPIPS Scores:** The Learned Perceptual Image Patch Similarity scores are computed using both the VGG and AlexNet models. These scores are derived from deep learning models and aim to provide a measure of perceptual similarity that more closely aligns with human visual perception.\n","\n"],"metadata":{"id":"R6WI8cWTF7Uo"}},{"cell_type":"markdown","source":["### **Step 6: Prepare the data for analysis**"],"metadata":{"id":"h9ujAxtEMIZx"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Create a dataframe to store the quality scores\n","df = pd.DataFrame({\n","    'Distorted Image': distorted_imgs,\n","    'Reference Image': reference_imgs,\n","    'DMOS Score': scores,\n","    'PSNR': psnr_scores,\n","    'SSIM': ssim_scores,\n","    'LPIPS (VGG)': lpips_vgg_scores,\n","    'LPIPS (AlexNet)': lpips_alexnet_scores\n","})\n","\n","# Remove rows with missing scores\n","df_valid = df.dropna(subset=['DMOS Score'])\n","\n","print(f\"Number of valid rows: {len(df_valid)}\")\n","print(f\"Number of removed rows: {len(df) - len(df_valid)}\")\n","\n","# Display the first few rows of the dataframe\n","print(\"\\nDataframe head:\")\n","print(df_valid.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkIqW65bXJIW","executionInfo":{"status":"ok","timestamp":1711986756980,"user_tz":-330,"elapsed":572,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"09b09b77-418d-46b1-847a-b94dc9bb4a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of valid rows: 143\n","Number of removed rows: 31\n","\n","Dataframe head:\n","    Distorted Image               Reference Image  DMOS Score       PSNR  \\\n","0  gblur/img156.bmp              refimgs/caps.bmp   42.127765   9.793991   \n","1   gblur/img98.bmp  refimgs/churchandcapitol.bmp   37.462720   7.582538   \n","2   gblur/img23.bmp           refimgs/monarch.bmp   43.264560  11.130536   \n","3   gblur/img40.bmp        refimgs/lighthouse.bmp   19.510097  11.426720   \n","4   gblur/img93.bmp             refimgs/plane.bmp   72.829422   7.305499   \n","\n","       SSIM  LPIPS (VGG)  LPIPS (AlexNet)  \n","0 -0.000998     0.833526         0.842938  \n","1 -0.000390     0.763065         0.810280  \n","2 -0.003895     0.853667         0.855812  \n","3  0.001432     0.804289         0.889132  \n","4  0.019894     0.752861         0.900414  \n"]}]},{"cell_type":"markdown","source":["**pd.DataFrame({...}):** A pandas DataFrame is created with columns labeled 'Distorted Image', 'Reference Image', 'DMOS Score', 'PSNR', 'SSIM', 'LPIPS (VGG)', and 'LPIPS (AlexNet)'. Each column is filled with the corresponding data from the lists populated in the previous steps. This structure allows for easy visualization and manipulation of the dataset, linking each distorted image to its reference, the human-assigned DMOS score, and the computed quality metrics."],"metadata":{"id":"hkbaAecEGaKH"}},{"cell_type":"markdown","source":["**df.dropna(subset=['DMOS Score']):** This line removes any rows from the DataFrame that have a missing ('NaN') value in the 'DMOS Score' column. The assumption here is that without a DMOS score, the row lacks the essential human opinion score needed for certain types of analysis, such as comparing human perception against computed quality metrics. The resulting DataFrame is stored in df_valid."],"metadata":{"id":"MA1oix6qGbkE"}},{"cell_type":"markdown","source":["### **Step 7: Compute correlation coefficients**"],"metadata":{"id":"Nv2nDeALXWnz"}},{"cell_type":"code","source":["from scipy.stats import spearmanr\n","\n","# Compute Spearman rank order correlation coefficients\n","spearman_psnr = spearmanr(df_valid['DMOS Score'], df_valid['PSNR'])[0]\n","spearman_ssim = spearmanr(df_valid['DMOS Score'], df_valid['SSIM'])[0]\n","spearman_lpips_vgg = spearmanr(df_valid['DMOS Score'], df_valid['LPIPS (VGG)'])[0]\n","spearman_lpips_alexnet = spearmanr(df_valid['DMOS Score'], df_valid['LPIPS (AlexNet)'])[0]\n","\n","print(\"Spearman rank order correlation coefficients:\")\n","print(f\"PSNR: {spearman_psnr:.4f}\")\n","print(f\"SSIM: {spearman_ssim:.4f}\")\n","print(f\"LPIPS (VGG): {spearman_lpips_vgg:.4f}\")\n","print(f\"LPIPS (AlexNet): {spearman_lpips_alexnet:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IJMHoZ5Xe79","executionInfo":{"status":"ok","timestamp":1711986843263,"user_tz":-330,"elapsed":383,"user":{"displayName":"Investing Filter","userId":"00097480192575946567"}},"outputId":"a9be8c95-84f1-465d-ee84-1e372200a527"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spearman rank order correlation coefficients:\n","PSNR: -0.0509\n","SSIM: -0.0386\n","LPIPS (VGG): 0.0407\n","LPIPS (AlexNet): 0.0692\n"]}]},{"cell_type":"markdown","source":["Based on the computed Spearman rank order correlation coefficients, we can make the following observations:\n","\n","- **PSNR:**\n","    - The correlation coefficient between PSNR and DMOS scores is $-0.0509$, which indicates a weak negative correlation.\n","    - This suggests that PSNR may not be a strong indicator of human perception of image quality for this dataset.\n","- **SSIM:**\n","    - The correlation coefficient between SSIM and DMOS scores is $-0.0386$, which also indicates a weak negative correlation.\n","    - Similar to PSNR, SSIM does not seem to correlate well with human perception of image quality for this dataset.\n","- **LPIPS (VGG):**\n","    - The correlation coefficient between LPIPS (VGG) and DMOS scores is $0.0407$, indicating a weak positive correlation.\n","    - While the correlation is slightly stronger than PSNR and SSIM, it is still relatively weak.\n","- **LPIPS (AlexNet):**\n","    - The correlation coefficient between LPIPS (AlexNet) and DMOS scores is $0.0692$, which is the highest among the evaluated metrics.\n","    - Although the correlation is still relatively weak, LPIPS (AlexNet) appears to have the strongest correlation with human perception of image quality among the considered metrics.\n","\n","**Comparing the performance of the quality metrics:**\n","\n","- LPIPS (AlexNet) has the highest absolute correlation coefficient ($0.0692$), indicating that it has the strongest correlation with human perception among the evaluated metrics.\n","- LPIPS (VGG) follows LPIPS (AlexNet) with a correlation coefficient of $0.0407$.\n","- PSNR and SSIM have negative correlation coefficients, suggesting that they may not be suitable for assessing image quality in this particular dataset.\n"],"metadata":{"id":"IHXEW5lFX-ZX"}}]}